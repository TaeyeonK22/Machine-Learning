# ML 5주차 정규과제

📌ML 정규과제는 매주 정해진 **유튜브 강의 영상을 통해 머신러닝 이론을 학습**한 후, 해당 내용을 바탕으로 **실습 문제를 풀어보며 이해도를 높이는 학습 방식**입니다. 

이번주는 아래의 **ML_5th_TIL**에 명시된 유튜브 강의를 먼저 수강해 주세요. 학습 중에는 주요 개념을 스스로 정리하고, 이해가 어려운 부분은 강의 자료나 추가 자료를 참고해 보완해주세요. 과제까지 다 작성한 이후에 Github를 과제 시트에 제출해주시면 됩니다.



**(수행 인증샷은 필수입니다.)** 

> 주어진 과제를 다 한 이후, 인증샷이나 따로 코드를 깃허브에 정리하여 제출해주세요.



## ML_5th_TIL

### 랜덤포레스트 모델

<br>



## 주차별 학습 (Study Schedule)

| 주차   | 공부 범위                              | 완료 여부 |
| ------ | -------------------------------------- | --------- |
| 1주차. | 선형 회귀 (Linear Regression) (1)      | ✅         |
| 2주차  | 선형 회귀 (Linear Regression) (2)      | ✅         |
| 3주차  | 로지스틱 회귀 (Logistic Regression)    | ✅         |
| 4주차  | 결정 트리 (Decision Tree)              | ✅         |
| 5주차  | 앙상블 : 랜덤 포레스트 (Random Forest) | ✅         |
| 6주차  | 주성분 분석 (PCA)                      | 🍽️         |
| 7주차  | K - 평균 군집화                        | 🍽️         |

<!-- 여기까진 그대로 둬 주세요-->



---

# 1️⃣ 개념 정리

## 01. 랜덤포레스트 모델

```
✅ 학습 목표 :
* 랜덤 포레스트(Random Forest)의 개념과 필요성을 이해할 수 있다.
* Bagging과 Random Subspace의 원리와 역할을 이해할 수 있다.
* 랜덤 포레스트의 Generalization Error 개념을 이해할 수 있다.
* Out-of-Bag(OOB) Error와 변수 중요도 평가 방법을 이해할 수 있다.
* 랜덤 포레스트 모델의 주요 하이퍼파라미터를 이해하고 설정할 수 있다. 
```

<!-- 새롭게 배운 내용을 자유롭게 정리해주세요.-->

### 01-1. 랜덤 포레스트(Random Forest)의 개념과 필요성을 이해할 수 있다.

- 랜덤 포레스트의 필요성
  - 개별 트리 모델의 단점
    1. 계층적 구조로 인해 중간에 에러가 발생하면 다음 단계로 에러가 계속 전파
    1. 학습 데이터의 미세한 변동에도 최종 결과 크게 영향(적은 개수의 노이즈에도 크게 영향)
    1. 나무의 최종 노드 개수를 늘리면 과적합 위험(Low Bias, Large Variance)
  - 해결 방안: 랜덤 포레스트

- 랜덤 포레스트
  - 앙상블: 여러 Base 모델들의 다수결 법칙 또는 평균을 이용해 통합하여 예측 정확성을 향상시키는 방법
  - 다음 조건을 만족할 때, 앙상블 모델은 Base 모델보다 우수한 성능을 보여줌
    1. Base 모델들이 서로 독립적
    1. Base 모델들이 무작위 예측을 수행하는 모델보다 성능이 좋은 경우

### 01-1*&nbsp;GPT 정리<br> 

여기서 말하는 **Base 모델(Base Learner)** 은 바로 **개별 의사결정나무(Decision Tree)** 를 의미합니다.

---

#### 🌳 랜덤포레스트(Random Forest)의 구조 요약

| 구성요소                   | 설명                                        |
| ---------------------- | ----------------------------------------- |
| **Base Model (기저 모델)** | **여러 개의 Decision Tree** 각각을 의미            |
| **앙상블 방법**             | 여러 트리의 결과를 **평균(회귀)** 또는 **다수결(분류)** 로 통합 |
| **최종 예측값**             | 각 트리의 예측을 종합한 결과                          |

---

#### ⚙️ 학습 과정 간단히 보면

1. **Bootstrap Sampling**

   * 원본 데이터에서 **랜덤하게 일부 표본을 복원추출**하여 각 트리를 학습
   * → 트리마다 조금씩 다른 데이터를 학습하게 됨

2. **Feature Randomness (특성 랜덤성)**

   * 각 트리 분할 시, 모든 변수를 고려하지 않고 **일부 랜덤하게 선택된 변수들만 사용**
   * → 트리 간 **상관성(의존성)** 줄이기

3. **앙상블 (Ensemble)**

   * 분류 문제: **다수결 투표**
   * 회귀 문제: **평균값 계산**

---

#### 💡 왜 Base 모델이 독립적이어야 하나?

* 트리들이 서로 너무 비슷하면 (= 완전히 같은 데이터, 같은 변수 사용)
  → 예측도 비슷해서 **앙상블 효과가 줄어듦**
* 서로 다른 부분을 배운 트리들이 모이면
  → 개별 오류가 상쇄되어 **안정적이고 일반화 성능이 좋은 모델** 완성

---

👉 정리하면,

* 랜덤포레스트의 **Base 모델 = 여러 개의 의사결정나무** 🌲🌲🌲
* 트리 간의 **무작위성(randomness)** 덕분에 서로 독립성을 확보하고,
* 이를 **앙상블(평균/다수결)** 하여 더 강력한 예측 성능을 얻는 구조입니다.




### 01-2. Bagging과 Random Subspace의 원리와 역할을 이해할 수 있다.




### 01-3. Out-of-Bag(OOB) Error와 변수 중요도 평가 방법을 이해할 수 있다.




### 01-4. 랜덤 포레스트 모델의 주요 하이퍼파라미터를 이해하고 설정할 수 있다




<br>
<br>

---

# 2️⃣ 과제

> **4주차에 진행했던 와인 품질 데이터셋에 대해 랜덤 포레스트 모델을 적용해봅시다. `feature_importances`속성을 추출하여 어떤 변수들이 와인 품질 예측에 가장 중요한 역할을 하는지 시각화(막대 그래프)하고, 이번에는 상위 3개의 변수에 대해 설명하는 주피터 노트북을 작성해주세요.**



~~~
과제 가이드
1. 모델 학습
- 4주차에 사용한 와인 품질 데이터셋 재활용
- from sklearn.ensemble import RandomForestClassifier
- model.fit(X_train, y_train)으로 학습을 한다. 
- feature_importance 를 분석하여, 어떤 변수가 예측에 중요한 역할을 하는지 해석한다. 

* 힌트
- feature_importance란.? : 랜덤포레스트는 어떤 변수가 분할 시 예측 성능에 향상에 기여했는지를 평가한다.
- 즉 값이 클수록 중요하다. 
~~~



<br>

### 🎉 수고하셨습니다.